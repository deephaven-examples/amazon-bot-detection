{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6dc2e8-e4b2-40cb-b439-3b3e7571dbf1",
   "metadata": {},
   "source": [
    "First, import the libraries needed to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f61fe0-80d3-431c-9b2f-140e2d6cb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import datetime as dt\n",
    "\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337d9b3-6ee5-40cd-b88b-206c3eed4a2c",
   "metadata": {},
   "source": [
    "Next, set `NUM_PROC` equal to the number of processors on your machine. This step is important, as it significantly impacts the download speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340aedd9-edc2-498a-8086-c41d609f0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROC = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119581d1-9191-41b4-be7e-ca9ee1fbe682",
   "metadata": {},
   "source": [
    "Now, create a list of the dataset names for downloading, and define a start time to avoid downloading all of the data. If you want to work with less data, you can leave some categories out of the list, or increase the start time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08012d-ad30-4955-9d9a-eab17e1e67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of all dataset categories\n",
    "names = [\n",
    "    'All_Beauty',\n",
    "    'Toys_and_Games',\n",
    "    'Cell_Phones_and_Accessories',\n",
    "    'Industrial_and_Scientific',\n",
    "    'Gift_Cards',\n",
    "    'Musical_Instruments',\n",
    "    'Electronics',\n",
    "    'Handmade_Products',\n",
    "    'Arts_Crafts_and_Sewing',\n",
    "    'Baby_Products',\n",
    "    'Health_and_Household',\n",
    "    'Office_Products',\n",
    "    'Digital_Music',\n",
    "    'Grocery_and_Gourmet_Food',\n",
    "    'Sports_and_Outdoors',\n",
    "    'Home_and_Kitchen',\n",
    "    'Subscription_Boxes',\n",
    "    'Tools_and_Home_Improvement',\n",
    "    'Pet_Supplies',\n",
    "    'Video_Games',\n",
    "    'Kindle_Store',\n",
    "    'Clothing_Shoes_and_Jewelry',\n",
    "    'Patio_Lawn_and_Garden',\n",
    "    'Unknown',\n",
    "    'Books',\n",
    "    'Automotive',\n",
    "    'CDs_and_Vinyl',\n",
    "    'Beauty_and_Personal_Care',\n",
    "    'Amazon_Fashion',\n",
    "    'Magazine_Subscriptions',\n",
    "    'Software',\n",
    "    'Health_and_Personal_Care',\n",
    "    'Appliances',\n",
    "    'Movies_and_TV'\n",
    "]\n",
    "\n",
    "# only want to look at data in 2023 - get Jan 1 2023 and convert to millis since epoch\n",
    "start_time_millis = dt.datetime(2023, 1, 1, 0, 0, 0, tzinfo=dt.timezone.utc).timestamp() * 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb68cf-9266-456a-86e1-e256055721dd",
   "metadata": {},
   "source": [
    "Finally, download and filter the data, and write the results to `/amazon-data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631b458-24b4-4fd5-8117-10965ecb0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download relevant portions of each dataset and write to local parquet\n",
    "for name in names:\n",
    "\n",
    "    # download and filter review data if it does not exist\n",
    "    if not os.path.exists(f\"../amazon-data/reviews/{name}.parquet\"):\n",
    "        print(f\"Writing {name} review data...\")\n",
    "        \n",
    "        # load review data\n",
    "        review_dataset = datasets.load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "            f\"raw_review_{name}\",\n",
    "            num_proc=NUM_PROC,\n",
    "            trust_remote_code=True)['full']\n",
    "        \n",
    "        # select columns of interest and filter for post-2023 before writing\n",
    "        filtered_review_dataset = (\n",
    "            review_dataset\n",
    "            .select_columns([\"rating\", \"title\", \"text\", \"parent_asin\", \"user_id\", \"timestamp\"])\n",
    "            .filter(lambda timestamp: timestamp >= start_time_millis, input_columns=\"timestamp\")\n",
    "        )\n",
    "        filtered_review_dataset.to_parquet(f\"../amazon-data/reviews/{name}.parquet\")\n",
    "\n",
    "    if not os.path.exists(f\"../amazon-data/items/{name}.parquet\"):\n",
    "        print(f\"Writing {name} item data...\")\n",
    "        \n",
    "        # load item metadata\n",
    "        meta_dataset = datasets.load_dataset(\n",
    "            \"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "            f\"raw_meta_{name}\",\n",
    "            num_proc=NUM_PROC,\n",
    "            trust_remote_code=True)['full']\n",
    "        \n",
    "        # select columns of interest before writing\n",
    "        filtered_meta_dataset = (\n",
    "            meta_dataset\n",
    "            .select_columns([\"main_category\", \"title\", \"average_rating\", \"rating_number\", \"parent_asin\"])\n",
    "        )\n",
    "        filtered_meta_dataset.to_parquet(f\"../amazon-data/items/{name}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dh-amazon-venv)",
   "language": "python",
   "name": "dh-amazon-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
