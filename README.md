# Real-time Amazon bot detection with BERT and Deephaven

This example uses Deephaven to perform real-time predictions of whether or not an Amazon review was generated by ChatGPT. The data comes from the [Amazon Reviews Dataset](https://amazon-reviews-2023.github.io), collected by [Julian McAuley's lab](https://cseweb.ucsd.edu/~jmcauley/) and hosted on [Huggingface](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023).

The model used for bot prediction comes from [Vidhi Kishor Waghela's entry](https://www.kaggle.com/code/vidhikishorwaghela/llm-detect-ai-generated-text) in a [ChatGPT-generated text detection Kaggle competition](https://www.kaggle.com/competitions/llm-detect-ai-generated-text). The detector training data, script, and resulting PyTorch model are stored in the [`detector`](https://github.com/deephaven-examples/amazon-bot-detection/tree/main/detector) directory.

This Deephaven example can be run in Jupyter using Deephaven's [Python package](https://pypi.org/project/deephaven-server/), or inside of a Docker container.  We've provided scripts, notebooks, and instructions for each of [Jupyter](#jupyter) and [Docker](#docker), so pick the path that feels most comfortable to you.

## Jupyter

Deephaven's Python package requires Java 17 or higher to be installed on your machine. See [this page](https://deephaven.io/core/docs/getting-started/launch-build/#prerequisites) for OS-specific instructions on installing Java.

### Set up the environment

1. Navigate to the `jupyter` subdirectory:
   ```bash
   cd jupyter
   ```

2. Then, execute a script to set up the environment:
   ```bash
   chmod +x create-venv.sh
   ./create-venv.sh
   ```

   This creates a Python virtual environment called `dh-amazon-venv` and installs all of the required Python packages into that environment.

3. Next, activate the environment and start Jupyter:
   ```bash
   source dh-amazon-venv/bin/activate
   jupyter notebook
   ```

Once you've started Jupyter, you're ready to go!

### Download the data

This step only needs to be done once, and can take quite a while, depending on the speed of your internet connection and the processing power of your machine. It took about 20 minutes on a Macbook Pro M2 with 8 cores.

1. Open the `download_data.ipynb` notebook and select the `dh-amazon-venv` kernel.

2. Set the `NUM_PROC` variable at the top of the second cell equal to the number of processors available to you. This has a significant impact on the download speed.

3. Run the whole notebook. This will download the Amazon data, filter it for 2023, and write it to the `amazon-data` directory in Parquet format.

### Run the example

Finally, navigate to the `detect_bots.ipynb` notebook and select the `dh-amazon-venv` kernel. This notebook walks you through the whole example, and gives you the opportunity to play with Deephaven. We hope you learn something new!

## Docker

To run this example with Docker, you must have Docker installed on your machine. See [this guide](https://docs.docker.com/engine/install/) for OS-specific instructions.

### Start the Deephaven server

1. Navigate to the `docker` subdirectory:
   ```bash
   cd docker
   ```

2. Build and run the Docker image using `docker-compose`:
   ```bash
   docker compose up
   ```

3. Once the image is built, navigate to the Deephaven IDE at `http://localhost:10000/ide/`.

The Deephaven IDE contains all of the scripts associated to this example. Let's get started!

### Download the data

This step only needs to be done once, and can take quite a while, depending on the speed of your internet connection and the processing power of your machine. It took about 20 minutes on a Macbook Pro M2 with 8 cores. You may need to allocate more resources to the Docker engine to access the full capabilities of your machine. This can be done using [Docker Desktop](https://www.docker.com/products/docker-desktop/). See [this guide](https://docs.docker.com/desktop/settings/mac/#resources) for more details.

1. In the right-hand sidebar, open the `download_data.py` script.

2. Set the `NUM_PROC` variable in line 8 equal to the number of processors available to you. This has a significant impact on the download speed.

3. Run the script using the "play" button at the top of the screen. This will download the Amazon data, filter it for 2023, and write it to the `amazon-data` directory in Parquet format.

### Run the example

Once you've downloaded the data, you're ready to start working with the example. The code is divided between two scripts, `stream_data.py` and `detect_bots.py`. Running `detect_bots.py` will also execute `stream_data.py`, so you can start there if you'd like. We hope you enjoy this example!